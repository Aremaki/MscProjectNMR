{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Import urine spectra with concentration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install project packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///data/ar1220/MscProjectNMR\n",
      "Installing collected packages: MscProjectNMR\n",
      "  Attempting uninstall: MscProjectNMR\n",
      "    Found existing installation: MscProjectNMR 0\n",
      "    Uninstalling MscProjectNMR-0:\n",
      "      Successfully uninstalled MscProjectNMR-0\n",
      "  Running setup.py develop for MscProjectNMR\n",
      "Successfully installed MscProjectNMR-0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install -e ../."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import fucntions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "from tfrecords import write_tfrecords_concentrations, write_tfrecords_concentrations_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.a. Large dataset with independent metabolites (10 000 samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.1.a load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_spectrum_large = '../data/concentration_data/Large_sample/Spectra_Mixt1.txt'\n",
    "filename_concentrations_large = '../data/concentration_data/Large_sample/Concentrations_Mix1.txt'\n",
    "data_spectrum_large = np.loadtxt(filename_spectrum_large, dtype=float)\n",
    "data_concentrations_large = np.loadtxt(filename_concentrations_large, delimiter='\\t', dtype=float,\n",
    "                                usecols=range(1,data_spectrum_large.shape[1]+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert into dataframes\n",
    "df_spectrum_large = pd.DataFrame(data_spectrum_large).T\n",
    "df_concentrations_large = pd.DataFrame(data_concentrations_large).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.1.b Normalize the input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define minimum and maximum value of spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val = -50\n",
    "max_val = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df_spectrum_large = (df_spectrum_large - min_val)/(max_val - min_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.1.c. Standardise the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import mean concentration data and metabolites\n",
    "filename_mean_concentrations = '../data/concentration_data/normal_urine.txt'\n",
    "mean_concentrations = np.loadtxt(filename_mean_concentrations, delimiter='\\t', dtype=float, usecols=1, skiprows=1)\n",
    "sd_concentrations = np.loadtxt(filename_mean_concentrations, delimiter='\\t', dtype=float, usecols=2, skiprows=1)\n",
    "\n",
    "stand_df_concentrations_large = (df_concentrations_large - mean_concentrations)/sd_concentrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10000)\n",
      "(10000, 48)\n"
     ]
    }
   ],
   "source": [
    "print(norm_df_spectrum_large.shape)\n",
    "print(stand_df_concentrations_large.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.1.d.  Shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df_spectrum_large, stand_df_concentrations_large = shuffle(norm_df_spectrum_large, stand_df_concentrations_large)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.1.e.  Split data into train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_large, X_test_large, y_train_large, y_test_large = train_test_split(norm_df_spectrum_large,\n",
    "                                                                            stand_df_concentrations_large,\n",
    "                                                                            test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.1.f.  Convert into tf.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(10000,), dtype=tf.float64, name=None), TensorSpec(shape=(48,), dtype=tf.float64, name=None))\n",
      "(TensorSpec(shape=(10000,), dtype=tf.float64, name=None), TensorSpec(shape=(48,), dtype=tf.float64, name=None))\n"
     ]
    }
   ],
   "source": [
    "train_dataset_large = tf.data.Dataset.from_tensor_slices((X_train_large, y_train_large))\n",
    "val_dataset_large = tf.data.Dataset.from_tensor_slices((X_test_large, y_test_large))\n",
    "\n",
    "print(train_dataset_large.element_spec)\n",
    "print(val_dataset_large.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(10000,), dtype=tf.float64, name=None), TensorSpec(shape=(), dtype=tf.float64, name=None))\n",
      "(TensorSpec(shape=(10000,), dtype=tf.float64, name=None), TensorSpec(shape=(), dtype=tf.float64, name=None))\n"
     ]
    }
   ],
   "source": [
    "train_dataset_large_single = [tf.data.Dataset.from_tensor_slices((X_train_large,\n",
    "                                                                  y_train_large[y_train_large.columns[i]]))\n",
    "                              for i in range(48)]\n",
    "val_dataset_large_single = [tf.data.Dataset.from_tensor_slices((X_test_large,\n",
    "                                                                y_test_large[y_test_large.columns[i]]))\n",
    "                              for i in range(48)]\n",
    "\n",
    "print(train_dataset_large_single[0].element_spec)\n",
    "print(val_dataset_large_single[0].element_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.1.g.  Write tf.Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tfrecords_concentrations('../data/tfrecords/Concentrations_data/Large_sample/train',\n",
    "                               dataset=train_dataset_large, number=32)\n",
    "write_tfrecords_concentrations('../data/tfrecords/Concentrations_data/Large_sample/validation',\n",
    "                               dataset=val_dataset_large, number=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(48):\n",
    "    if not os.path.exists('../data/tfrecords/Concentrations_data/Large_sample_single/metabolite_{}/train'.format(i)):\n",
    "        os.makedirs('../data/tfrecords/Concentrations_data/Large_sample_single/metabolite_{}/train'.format(i))\n",
    "    if not os.path.exists('../data/tfrecords/Concentrations_data/Large_sample_single/metabolite_{}/validation'.format(i)):\n",
    "        os.makedirs('../data/tfrecords/Concentrations_data/Large_sample_single/metabolite_{}/validation'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(48):\n",
    "    write_tfrecords_concentrations_single('../data/tfrecords/Concentrations_data/Large_sample_single/metabolite_{}/train'.format(i),\n",
    "                               dataset=train_dataset_large_single[i], number=32)\n",
    "    write_tfrecords_concentrations('../data/tfrecords/Concentrations_data/Large_sample_single/metabolite_{}/validation'.format(i),\n",
    "                               dataset=val_dataset_large_single[i], number=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.2 Large dataset with correlated metabolites (10 000 samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.2.a load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_spectrum_large_corr = '../data/concentration_data/Large_correlated/Spectra_Mixt1.txt'\n",
    "filename_concentrations_large_corr = '../data/concentration_data/Large_correlated/Concentrations_Mix1.txt'\n",
    "data_spectrum_large_corr = np.loadtxt(filename_spectrum_large_corr, dtype=float)\n",
    "data_concentrations_large_corr = np.loadtxt(filename_concentrations_large_corr, delimiter='\\t', dtype=float,\n",
    "                                usecols=range(1,data_spectrum_large_corr.shape[1]+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert into dataframes\n",
    "df_spectrum_large_corr = pd.DataFrame(data_spectrum_large_corr).T\n",
    "df_concentrations_large_corr = pd.DataFrame(data_concentrations_large_corr).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.2.b Normalize the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df_spectrum_large_corr = (df_spectrum_large_corr - min_val)/(max_val - min_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.2.c Standardise the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import mean concentration data and metabolites\n",
    "filename_mean_concentrations = '../data/concentration_data/normal_urine.txt'\n",
    "mean_concentrations = np.loadtxt(filename_mean_concentrations, delimiter='\\t', dtype=float, usecols=1, skiprows=1)\n",
    "sd_concentrations = np.loadtxt(filename_mean_concentrations, delimiter='\\t', dtype=float, usecols=2, skiprows=1)\n",
    "\n",
    "stand_df_concentrations_large_corr = (df_concentrations_large_corr - mean_concentrations)/sd_concentrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10000)\n",
      "(10000, 48)\n"
     ]
    }
   ],
   "source": [
    "print(norm_df_spectrum_large_corr.shape)\n",
    "print(stand_df_concentrations_large_corr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.2.d Shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df_spectrum_large_corr, stand_df_concentrations_large_corr = shuffle(norm_df_spectrum_large_corr,\n",
    "                                                                          stand_df_concentrations_large_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.2.e Split data into train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_large_corr, X_test_large_corr, y_train_large_corr, y_test_large_corr = train_test_split(norm_df_spectrum_large_corr,\n",
    "                                                                                                stand_df_concentrations_large_corr,\n",
    "                                                                                                test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.2.f Convert into tf.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(10000,), dtype=tf.float64, name=None), TensorSpec(shape=(48,), dtype=tf.float64, name=None))\n",
      "(TensorSpec(shape=(10000,), dtype=tf.float64, name=None), TensorSpec(shape=(48,), dtype=tf.float64, name=None))\n"
     ]
    }
   ],
   "source": [
    "train_dataset_large_corr = tf.data.Dataset.from_tensor_slices((X_train_large_corr, y_train_large_corr))\n",
    "val_dataset_large_corr = tf.data.Dataset.from_tensor_slices((X_test_large_corr, y_test_large_corr))\n",
    "\n",
    "print(train_dataset_large_corr.element_spec)\n",
    "print(val_dataset_large_corr.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(10000,), dtype=tf.float64, name=None), TensorSpec(shape=(), dtype=tf.float64, name=None))\n",
      "(TensorSpec(shape=(10000,), dtype=tf.float64, name=None), TensorSpec(shape=(), dtype=tf.float64, name=None))\n"
     ]
    }
   ],
   "source": [
    "train_dataset_large_corr_single = [tf.data.Dataset.from_tensor_slices((X_train_large_corr,\n",
    "                                                                y_train_large_corr[y_train_large_corr.columns[i]]))\n",
    "                              for i in range(48)]\n",
    "val_dataset_large_corr_single = [tf.data.Dataset.from_tensor_slices((X_test_large_corr,\n",
    "                                                                y_test_large_corr[y_test_large_corr.columns[i]]))\n",
    "                              for i in range(48)]\n",
    "\n",
    "print(train_dataset_large_corr_single[0].element_spec)\n",
    "print(val_dataset_large_corr_single[0].element_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.2.g Write tf.Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tfrecords_concentrations('../data/tfrecords/Concentrations_data/Large_correlated/train',\n",
    "                               dataset=train_dataset_large_corr, number=32)\n",
    "write_tfrecords_concentrations('../data/tfrecords/Concentrations_data/Large_correlated/validation',\n",
    "                               dataset=val_dataset_large_corr, number=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for i in range(48):\n",
    "    if not os.path.exists('../data/tfrecords/Concentrations_data/Large_corr_single/metabolite_{}/train'.format(i)):\n",
    "        os.makedirs('../data/tfrecords/Concentrations_data/Large_corr_single/metabolite_{}/train'.format(i))\n",
    "    if not os.path.exists('../data/tfrecords/Concentrations_data/Large_corr_single/metabolite_{}/validation'.format(i)):\n",
    "        os.makedirs('../data/tfrecords/Concentrations_data/Large_corr_single/metabolite_{}/validation'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(48):\n",
    "    write_tfrecords_concentrations_single('../data/tfrecords/Concentrations_data/Large_corr_single/metabolite_{}/train'.format(i),\n",
    "                               dataset=train_dataset_large_corr_single[i], number=32)\n",
    "    write_tfrecords_concentrations('../data/tfrecords/Concentrations_data/Large_corr_single/metabolite_{}/validation'.format(i),\n",
    "                               dataset=val_dataset_large_corr_single[i], number=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.3 Small dataset with independent metabolites (1000 samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.3.a load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_spectrum_small = '../data/concentration_data/Small_sample/Spectra_Mixt1.txt'\n",
    "filename_concentrations_small = '../data/concentration_data/Small_sample/Concentrations_Mix1.txt'\n",
    "data_spectrum_small = np.loadtxt(filename_spectrum_small, dtype=float)\n",
    "data_concentrations_small = np.loadtxt(filename_concentrations_small, delimiter='\\t', dtype=float,\n",
    "                                usecols=range(1,data_spectrum_small.shape[1]+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert into dataframes\n",
    "df_spectrum_small = pd.DataFrame(data_spectrum_small).T\n",
    "df_concentrations_small = pd.DataFrame(data_concentrations_small).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.3.b Normalize the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df_spectrum_small = (df_spectrum_small - min_val)/(max_val - min_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.3.c Standardise the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import mean concentration data and metabolites\n",
    "filename_mean_concentrations = '../data/concentration_data/normal_urine.txt'\n",
    "mean_concentrations = np.loadtxt(filename_mean_concentrations, delimiter='\\t', dtype=float, usecols=1, skiprows=1)\n",
    "sd_concentrations = np.loadtxt(filename_mean_concentrations, delimiter='\\t', dtype=float, usecols=2, skiprows=1)\n",
    "\n",
    "stand_df_concentrations_small = (df_concentrations_small - mean_concentrations)/sd_concentrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10000)\n",
      "(1000, 48)\n"
     ]
    }
   ],
   "source": [
    "print(norm_df_spectrum_small.shape)\n",
    "print(stand_df_concentrations_small.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.3.d Shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df_spectrum_small, stand_df_concentrations_small = shuffle(norm_df_spectrum_small, stand_df_concentrations_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.3.e Split data into train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_small, X_test_small, y_train_small, y_test_small = train_test_split(norm_df_spectrum_small,\n",
    "                                                                            stand_df_concentrations_small,\n",
    "                                                                            test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.3.f Convert into tf.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(10000,), dtype=tf.float64, name=None), TensorSpec(shape=(48,), dtype=tf.float64, name=None))\n",
      "(TensorSpec(shape=(10000,), dtype=tf.float64, name=None), TensorSpec(shape=(48,), dtype=tf.float64, name=None))\n"
     ]
    }
   ],
   "source": [
    "train_dataset_small = tf.data.Dataset.from_tensor_slices((X_train_small, y_train_small))\n",
    "val_dataset_small = tf.data.Dataset.from_tensor_slices((X_test_small, y_test_small))\n",
    "\n",
    "print(train_dataset_small.element_spec)\n",
    "print(val_dataset_small.element_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.3.g Write tf.Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tfrecords_concentrations('../data/tfrecords/Concentrations_data/Small_sample/train',\n",
    "                               dataset=train_dataset_small, number=8)\n",
    "write_tfrecords_concentrations('../data/tfrecords/Concentrations_data/Small_sample/validation',\n",
    "                               dataset=val_dataset_small, number=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.4 Small dataset with correlated metabolites (1000 samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.4.a load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_spectrum_small_corr = '../data/concentration_data/Small_correlated/Spectra_Mixt1.txt'\n",
    "filename_concentrations_small_corr = '../data/concentration_data/Small_correlated/Concentrations_Mix1.txt'\n",
    "data_spectrum_small_corr = np.loadtxt(filename_spectrum_small_corr, dtype=float)\n",
    "data_concentrations_small_corr = np.loadtxt(filename_concentrations_small_corr, delimiter='\\t', dtype=float,\n",
    "                                usecols=range(1,data_spectrum_small_corr.shape[1]+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert into dataframes\n",
    "df_spectrum_small_corr = pd.DataFrame(data_spectrum_small_corr).T\n",
    "df_concentrations_small_corr = pd.DataFrame(data_concentrations_small_corr).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.4.b Normalize the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df_spectrum_small_corr = (df_spectrum_small_corr - min_val)/(max_val - min_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.4.c Standardise the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import mean concentration data and metabolites\n",
    "filename_mean_concentrations = '../data/concentration_data/normal_urine.txt'\n",
    "mean_concentrations = np.loadtxt(filename_mean_concentrations, delimiter='\\t', dtype=float, usecols=1, skiprows=1)\n",
    "sd_concentrations = np.loadtxt(filename_mean_concentrations, delimiter='\\t', dtype=float, usecols=2, skiprows=1)\n",
    "\n",
    "stand_df_concentrations_small_corr = (df_concentrations_small_corr - mean_concentrations)/sd_concentrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10000)\n",
      "(1000, 48)\n"
     ]
    }
   ],
   "source": [
    "print(norm_df_spectrum_small_corr.shape)\n",
    "print(stand_df_concentrations_small_corr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.4.d Shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df_spectrum_small_corr, stand_df_concentrations_small_corr = shuffle(norm_df_spectrum_small_corr,\n",
    "                                                                          stand_df_concentrations_small_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.4.e Split data into train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_small_corr, X_test_small_corr, y_train_small_corr, y_test_small_corr = train_test_split(norm_df_spectrum_small_corr,\n",
    "                                                                                                stand_df_concentrations_small_corr,\n",
    "                                                                                                test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.4.f Convert into tf.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(10000,), dtype=tf.float64, name=None), TensorSpec(shape=(48,), dtype=tf.float64, name=None))\n",
      "(TensorSpec(shape=(10000,), dtype=tf.float64, name=None), TensorSpec(shape=(48,), dtype=tf.float64, name=None))\n"
     ]
    }
   ],
   "source": [
    "train_dataset_small_corr = tf.data.Dataset.from_tensor_slices((X_train_small_corr, y_train_small_corr))\n",
    "val_dataset_small_corr = tf.data.Dataset.from_tensor_slices((X_test_small_corr, y_test_small_corr))\n",
    "\n",
    "print(train_dataset_small_corr.element_spec)\n",
    "print(val_dataset_small_corr.element_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.4.g Write tf.Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tfrecords_concentrations('../data/tfrecords/Concentrations_data/Small_correlated/train',\n",
    "                               dataset=train_dataset_small_corr, number=8)\n",
    "write_tfrecords_concentrations('../data/tfrecords/Concentrations_data/Small_correlated/validation',\n",
    "                               dataset=val_dataset_small_corr, number=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.5 Extra small dataset with independent metabolites (100 samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.5.a load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_spectrum_xsmall = '../data/concentration_data/Extra_small_sample/Spectra_Mixt1.txt'\n",
    "filename_concentrations_xsmall = '../data/concentration_data/Extra_small_sample/Concentrations_Mix1.txt'\n",
    "data_spectrum_xsmall = np.loadtxt(filename_spectrum_xsmall, dtype=float)\n",
    "data_concentrations_xsmall = np.loadtxt(filename_concentrations_xsmall, delimiter='\\t', dtype=float,\n",
    "                                usecols=range(1,data_spectrum_xsmall.shape[1]+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert into dataframes\n",
    "df_spectrum_xsmall = pd.DataFrame(data_spectrum_xsmall).T\n",
    "df_concentrations_xsmall = pd.DataFrame(data_concentrations_xsmall).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.5.b Normalize the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df_spectrum_xsmall = (df_spectrum_xsmall - min_val)/(max_val - min_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.5.c Standardise the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import mean concentration data and metabolites\n",
    "filename_mean_concentrations = '../data/concentration_data/normal_urine.txt'\n",
    "mean_concentrations = np.loadtxt(filename_mean_concentrations, delimiter='\\t', dtype=float, usecols=1, skiprows=1)\n",
    "sd_concentrations = np.loadtxt(filename_mean_concentrations, delimiter='\\t', dtype=float, usecols=2, skiprows=1)\n",
    "\n",
    "stand_df_concentrations_xsmall = (df_concentrations_xsmall - mean_concentrations)/sd_concentrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 10000)\n",
      "(100, 48)\n"
     ]
    }
   ],
   "source": [
    "print(norm_df_spectrum_xsmall.shape)\n",
    "print(stand_df_concentrations_xsmall.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.5.d Shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df_spectrum_xsmall, stand_df_concentrations_xsmall = shuffle(norm_df_spectrum_xsmall,\n",
    "                                                                  stand_df_concentrations_xsmall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.5.e Split data into train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_xsmall, X_test_xsmall, y_train_xsmall, y_test_xsmall = train_test_split(norm_df_spectrum_xsmall,\n",
    "                                                                                stand_df_concentrations_xsmall,\n",
    "                                                                                test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.5.f Convert into tf.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(10000,), dtype=tf.float64, name=None), TensorSpec(shape=(48,), dtype=tf.float64, name=None))\n",
      "(TensorSpec(shape=(10000,), dtype=tf.float64, name=None), TensorSpec(shape=(48,), dtype=tf.float64, name=None))\n"
     ]
    }
   ],
   "source": [
    "train_dataset_xsmall = tf.data.Dataset.from_tensor_slices((X_train_xsmall, y_train_xsmall))\n",
    "val_dataset_xsmall = tf.data.Dataset.from_tensor_slices((X_test_xsmall, y_test_xsmall))\n",
    "\n",
    "print(train_dataset_xsmall.element_spec)\n",
    "print(.element_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.5.g Write tf.Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tfrecords_concentrations('../data/tfrecords/Concentrations_data/Extra_small_sample/train',\n",
    "                               dataset=train_dataset_xsmall, number=4)\n",
    "write_tfrecords_concentrations('../data/tfrecords/Concentrations_data/Extra_small_sample/validation',\n",
    "                               dataset=val_dataset_xsmall, number=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.6 Extra small dataset with correlated metabolites (100 samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.6.a load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_spectrum_xsmall_corr = '../data/concentration_data/Extra_small_correlated/Spectra_Mixt1.txt'\n",
    "filename_concentrations_xsmall_corr = '../data/concentration_data/Extra_small_correlated/Concentrations_Mix1.txt'\n",
    "data_spectrum_xsmall_corr = np.loadtxt(filename_spectrum_xsmall_corr, dtype=float)\n",
    "data_concentrations_xsmall_corr = np.loadtxt(filename_concentrations_xsmall_corr, delimiter='\\t', dtype=float,\n",
    "                                usecols=range(1,data_spectrum_xsmall_corr.shape[1]+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert into dataframes\n",
    "df_spectrum_xsmall_corr = pd.DataFrame(data_spectrum_xsmall_corr).T\n",
    "df_concentrations_xsmall_corr = pd.DataFrame(data_concentrations_xsmall_corr).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.6.b Normalize the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df_spectrum_xsmall_corr = (df_spectrum_xsmall_corr - min_val)/(max_val - min_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.6.c Standardise the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import mean concentration data and metabolites\n",
    "filename_mean_concentrations = '../data/concentration_data/normal_urine.txt'\n",
    "mean_concentrations = np.loadtxt(filename_mean_concentrations, delimiter='\\t', dtype=float, usecols=1, skiprows=1)\n",
    "sd_concentrations = np.loadtxt(filename_mean_concentrations, delimiter='\\t', dtype=float, usecols=2, skiprows=1)\n",
    "\n",
    "stand_df_concentrations_xsmall_corr = (df_concentrations_xsmall_corr - mean_concentrations)/sd_concentrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 10000)\n",
      "(100, 48)\n"
     ]
    }
   ],
   "source": [
    "print(norm_df_spectrum_xsmall_corr.shape)\n",
    "print(stand_df_concentrations_xsmall_corr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.6.d Shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df_spectrum_xsmall_corr, stand_df_concentrations_xsmall_corr = shuffle(norm_df_spectrum_xsmall_corr,\n",
    "                                                                            stand_df_concentrations_xsmall_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.6.e Split data into train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_xsmall_corr, X_test_xsmall_corr, y_train_xsmall_corr, y_test_xsmall_corr = train_test_split(norm_df_spectrum_xsmall_corr,\n",
    "                                                                                                    stand_df_concentrations_xsmall_corr,\n",
    "                                                                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.6.f Convert into tf.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(10000,), dtype=tf.float64, name=None), TensorSpec(shape=(48,), dtype=tf.float64, name=None))\n",
      "(TensorSpec(shape=(10000,), dtype=tf.float64, name=None), TensorSpec(shape=(48,), dtype=tf.float64, name=None))\n"
     ]
    }
   ],
   "source": [
    "train_dataset_xsmall_corr = tf.data.Dataset.from_tensor_slices((X_train_xsmall_corr, y_train_xsmall_corr))\n",
    "val_dataset_xsmall_corr = tf.data.Dataset.from_tensor_slices((X_test_xsmall_corr, y_test_xsmall_corr))\n",
    "\n",
    "print(train_dataset_xsmall_corr.element_spec)\n",
    "print(val_dataset_xsmall_corr.element_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.6.g Write tf.Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tfrecords_concentrations('../data/tfrecords/Concentrations_data/Extra_small_correlated/train',\n",
    "                               dataset=train_dataset_xsmall_corr, number=4)\n",
    "write_tfrecords_concentrations('../data/tfrecords/Concentrations_data/Extra_small_correlated/validation',\n",
    "                               dataset=val_dataset_xsmall_corr, number=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.7 Test dataset with independent metabolites (1000 samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.7.a load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_spectrum_test = '../data/concentration_data/Test_independent/Spectra_Mixt1.txt'\n",
    "filename_concentrations_test = '../data/concentration_data/Test_independent/Concentrations_Mix1.txt'\n",
    "data_spectrum_test = np.loadtxt(filename_spectrum_test, dtype=float)\n",
    "data_concentrations_test = np.loadtxt(filename_concentrations_test, delimiter='\\t', dtype=float,\n",
    "                                usecols=range(1,data_spectrum_test.shape[1]+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert into dataframes\n",
    "df_spectrum_test = pd.DataFrame(data_spectrum_test).T\n",
    "df_concentrations_test = pd.DataFrame(data_concentrations_test).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.7.b Normalize the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df_spectrum_test = (df_spectrum_test - min_val)/(max_val - min_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.7.c Standardise the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import mean concentration data and metabolites\n",
    "filename_mean_concentrations = '../data/concentration_data/normal_urine.txt'\n",
    "mean_concentrations = np.loadtxt(filename_mean_concentrations, delimiter='\\t', dtype=float, usecols=1, skiprows=1)\n",
    "sd_concentrations = np.loadtxt(filename_mean_concentrations, delimiter='\\t', dtype=float, usecols=2, skiprows=1)\n",
    "\n",
    "stand_df_concentrations_test = (df_concentrations_test - mean_concentrations)/sd_concentrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10000)\n",
      "(1000, 48)\n"
     ]
    }
   ],
   "source": [
    "print(norm_df_spectrum_test.shape)\n",
    "print(stand_df_concentrations_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.7.d Shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df_spectrum_test, stand_df_concentrations_test = shuffle(norm_df_spectrum_test, stand_df_concentrations_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.7.e Convert into tf.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(10000,), dtype=tf.float64, name=None), TensorSpec(shape=(48,), dtype=tf.float64, name=None))\n"
     ]
    }
   ],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices((norm_df_spectrum_test, stand_df_concentrations_test))\n",
    "\n",
    "print(test_dataset.element_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.7.f Write tf.Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tfrecords_concentrations('../data/tfrecords/Concentrations_data/Test_independent',\n",
    "                               dataset=test_dataset, number=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.8 Test dataset with correlated metabolites (1000 samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.8.a load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_spectrum_test_corr = '../data/concentration_data/Test_correlated/Spectra_Mixt1.txt'\n",
    "filename_concentrations_test_corr = '../data/concentration_data/Test_correlated/Concentrations_Mix1.txt'\n",
    "data_spectrum_test_corr = np.loadtxt(filename_spectrum_test_corr, dtype=float)\n",
    "data_concentrations_test_corr = np.loadtxt(filename_concentrations_test_corr, delimiter='\\t', dtype=float,\n",
    "                                usecols=range(1,data_spectrum_test_corr.shape[1]+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert into dataframes\n",
    "df_spectrum_test_corr = pd.DataFrame(data_spectrum_test_corr).T\n",
    "df_concentrations_test_corr = pd.DataFrame(data_concentrations_test_corr).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.8.b Normalize the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df_spectrum_test_corr = (df_spectrum_test_corr - min_val)/(max_val - min_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.8.c Standardise the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import mean concentration data and metabolites\n",
    "filename_mean_concentrations = '../data/concentration_data/normal_urine.txt'\n",
    "mean_concentrations = np.loadtxt(filename_mean_concentrations, delimiter='\\t', dtype=float, usecols=1, skiprows=1)\n",
    "sd_concentrations = np.loadtxt(filename_mean_concentrations, delimiter='\\t', dtype=float, usecols=2, skiprows=1)\n",
    "\n",
    "stand_df_concentrations_test_corr = (df_concentrations_test_corr - mean_concentrations)/sd_concentrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10000)\n",
      "(1000, 48)\n"
     ]
    }
   ],
   "source": [
    "print(norm_df_spectrum_test_corr.shape)\n",
    "print(stand_df_concentrations_test_corr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.8.d Shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df_spectrum_test_corr, stand_df_concentrations_test_corr = shuffle(norm_df_spectrum_test_corr,\n",
    "                                                                        stand_df_concentrations_test_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.8.e Convert into tf.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(10000,), dtype=tf.float64, name=None), TensorSpec(shape=(48,), dtype=tf.float64, name=None))\n"
     ]
    }
   ],
   "source": [
    "test_corr_dataset = tf.data.Dataset.from_tensor_slices((norm_df_spectrum_test_corr,\n",
    "                                                        stand_df_concentrations_test_corr))\n",
    "\n",
    "print(test_corr_dataset.element_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.8.f Write tf.Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tfrecords_concentrations('../data/tfrecords/Concentrations_data/Test_correlated',\n",
    "                               dataset=test_corr_dataset, number=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.9 Test abnormal urine dataset with independent metabolites (1000 samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.9.a load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_spectrum_abn_test = '../data/concentration_data/Test_abnormal/Spectra_Mix2.txt'\n",
    "filename_concentrations_abn_test = '../data/concentration_data/Test_abnormal/Concentrations_Mix2.txt'\n",
    "data_spectrum_abn_test = np.loadtxt(filename_spectrum_abn_test, dtype=float)\n",
    "data_concentrations_abn_test = np.loadtxt(filename_concentrations_abn_test, delimiter='\\t', dtype=float,\n",
    "                                usecols=range(1,data_spectrum_abn_test.shape[1]+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert into dataframes\n",
    "df_spectrum_abn_test = pd.DataFrame(data_spectrum_abn_test).T\n",
    "df_concentrations_abn_test = pd.DataFrame(data_concentrations_abn_test).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.9.b Normalize the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df_spectrum_abn_test = (df_spectrum_abn_test - min_val)/(max_val - min_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.9.c Standardise the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import mean concentration data and metabolites\n",
    "filename_mean_concentrations = '../data/concentration_data/normal_urine.txt'\n",
    "mean_concentrations = np.loadtxt(filename_mean_concentrations, delimiter='\\t', dtype=float, usecols=1, skiprows=1)\n",
    "sd_concentrations = np.loadtxt(filename_mean_concentrations, delimiter='\\t', dtype=float, usecols=2, skiprows=1)\n",
    "\n",
    "stand_df_concentrations_abn_test = (df_concentrations_abn_test - mean_concentrations)/sd_concentrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10000)\n",
      "(1000, 48)\n"
     ]
    }
   ],
   "source": [
    "print(norm_df_spectrum_abn_test.shape)\n",
    "print(stand_df_concentrations_abn_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.9.d Shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df_spectrum_abn_test, stand_df_concentrations_abn_test = shuffle(norm_df_spectrum_abn_test,\n",
    "                                                                      stand_df_concentrations_abn_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.9.e Convert into tf.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(10000,), dtype=tf.float64, name=None), TensorSpec(shape=(48,), dtype=tf.float64, name=None))\n"
     ]
    }
   ],
   "source": [
    "abn_test_dataset = tf.data.Dataset.from_tensor_slices((norm_df_spectrum_abn_test, stand_df_concentrations_abn_test))\n",
    "\n",
    "print(abn_test_dataset.element_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.9.f Write tf.Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tfrecords_concentrations('../data/tfrecords/Concentrations_data/Test_abnormal',\n",
    "                               dataset=abn_test_dataset, number=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.10 Test abnormal urine dataset with correlated metabolites (1000 samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.10.a load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_spectrum_abn_test_corr = '../data/concentration_data/Test_abnormal_corr/Spectra_Mix2.txt'\n",
    "filename_concentrations_abn_test_corr = '../data/concentration_data/Test_abnormal_corr/Concentrations_Mix2.txt'\n",
    "data_spectrum_abn_test_corr = np.loadtxt(filename_spectrum_abn_test_corr, dtype=float)\n",
    "data_concentrations_abn_test_corr = np.loadtxt(filename_concentrations_abn_test_corr, delimiter='\\t', dtype=float,\n",
    "                                usecols=range(1,data_spectrum_abn_test_corr.shape[1]+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert into dataframes\n",
    "df_spectrum_abn_test_corr = pd.DataFrame(data_spectrum_abn_test_corr).T\n",
    "df_concentrations_abn_test_corr = pd.DataFrame(data_concentrations_abn_test_corr).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.10.b Normalize the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df_spectrum_abn_test_corr = (df_spectrum_abn_test_corr - min_val)/(max_val - min_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.10.c Standardise the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import mean concentration data and metabolites\n",
    "filename_mean_concentrations = '../data/concentration_data/normal_urine.txt'\n",
    "mean_concentrations = np.loadtxt(filename_mean_concentrations, delimiter='\\t', dtype=float, usecols=1, skiprows=1)\n",
    "sd_concentrations = np.loadtxt(filename_mean_concentrations, delimiter='\\t', dtype=float, usecols=2, skiprows=1)\n",
    "\n",
    "stand_df_concentrations_abn_test_corr = (df_concentrations_abn_test_corr - mean_concentrations)/sd_concentrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10000)\n",
      "(1000, 48)\n"
     ]
    }
   ],
   "source": [
    "print(norm_df_spectrum_abn_test_corr.shape)\n",
    "print(stand_df_concentrations_abn_test_corr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.10.d Shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df_spectrum_abn_test_corr, stand_df_concentrations_abn_test_corr = shuffle(norm_df_spectrum_abn_test_corr,\n",
    "                                                                        stand_df_concentrations_abn_test_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.10.e Convert into tf.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(10000,), dtype=tf.float64, name=None), TensorSpec(shape=(48,), dtype=tf.float64, name=None))\n"
     ]
    }
   ],
   "source": [
    "abn_test_corr_dataset = tf.data.Dataset.from_tensor_slices((norm_df_spectrum_abn_test_corr,\n",
    "                                                        stand_df_concentrations_abn_test_corr))\n",
    "\n",
    "print(abn_test_corr_dataset.element_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.10.f Write tf.Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tfrecords_concentrations('../data/tfrecords/Concentrations_data/Test_abnormal_corr',\n",
    "                               dataset=abn_test_corr_dataset, number=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
