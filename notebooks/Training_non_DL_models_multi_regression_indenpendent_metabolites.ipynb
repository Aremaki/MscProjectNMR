{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Training of non-DL models for Multi-regression of the metabolites concentrations on indenpendent metabolites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install project packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Obtaining file:///data/ar1220/MscProjectNMR\n",
      "Installing collected packages: MscProjectNMR\n",
      "  Attempting uninstall: MscProjectNMR\n",
      "    Found existing installation: MscProjectNMR 0\n",
      "    Uninstalling MscProjectNMR-0:\n",
      "      Successfully uninstalled MscProjectNMR-0\n",
      "  Running setup.py develop for MscProjectNMR\n",
      "Successfully installed MscProjectNMR-0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install -e ../."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import fucntions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "from tfrecords import read_tfrecords_concentrations, read_tfrecords_concentrations_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# I. Read the tf.Record files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.1 Small independent dataset (1000 spectra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_file_paths = ['../data/tfrecords/Concentrations_data/Small_sample/train/data_{}.tfrecord'.format(i)\n",
    "                    for i in range(8)]\n",
    "small_val_file_paths = ['../data/tfrecords/Concentrations_data/Small_sample/validation/data_{}.tfrecord'.format(i)\n",
    "                    for i in range(2)]\n",
    "\n",
    "small_train_dataset = read_tfrecords_concentrations(small_train_file_paths, 32)\n",
    "\n",
    "small_val_dataset = read_tfrecords_concentrations(small_val_file_paths, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = []\n",
    "y_train_small = []\n",
    "\n",
    "for element in small_train_dataset.unbatch():\n",
    "    X_train_small.append(element[0].numpy())\n",
    "    y_train_small.append(element[1].numpy())\n",
    "    \n",
    "for element in small_val_dataset.unbatch():\n",
    "    X_train_small.append(element[0].numpy())\n",
    "    y_train_small.append(element[1].numpy())\n",
    "\n",
    "X_train_small = pd.DataFrame(X_train_small)\n",
    "y_train_small = pd.DataFrame(y_train_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.2 Large independent dataset (10000 spectra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_train_file_paths = ['../data/tfrecords/Concentrations_data/Large_sample/train/data_{}.tfrecord'.format(i) \n",
    "                        for i in range(32)]\n",
    "large_val_file_paths = ['../data/tfrecords/Concentrations_data/Large_sample/validation/data_{}.tfrecord'.format(i) \n",
    "                      for i in range(8)]\n",
    "\n",
    "large_train_dataset = read_tfrecords_concentrations(large_train_file_paths, 64)\n",
    "\n",
    "large_val_dataset = read_tfrecords_concentrations(large_val_file_paths, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_large = []\n",
    "y_train_large = []\n",
    "\n",
    "for element in large_train_dataset.unbatch():\n",
    "    X_train_large.append(element[0].numpy())\n",
    "    y_train_large.append(element[1].numpy())\n",
    "    \n",
    "for element in large_val_dataset.unbatch():\n",
    "    X_train_large.append(element[0].numpy())\n",
    "    y_train_large.append(element[1].numpy())\n",
    "\n",
    "X_train_large = pd.DataFrame(X_train_large)\n",
    "y_train_large = pd.DataFrame(y_train_large)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.3 Extra small independent dataset (100 spectra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xsmall_train_file_paths = ['../data/tfrecords/Concentrations_data/Extra_small_sample/train/data_{}.tfrecord'\n",
    "                           .format(i) for i in range(4)]\n",
    "xsmall_val_file_paths = ['../data/tfrecords/Concentrations_data/Extra_small_sample/validation/data_{}.tfrecord'\n",
    "                         .format(i) for i in range(1)]\n",
    "\n",
    "xsmall_train_dataset = read_tfrecords_concentrations(xsmall_train_file_paths, 16)\n",
    "\n",
    "xsmall_val_dataset = read_tfrecords_concentrations(xsmall_val_file_paths, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_xsmall = []\n",
    "y_train_xsmall = []\n",
    "\n",
    "for element in xsmall_train_dataset.unbatch():\n",
    "    X_train_xsmall.append(element[0].numpy())\n",
    "    y_train_xsmall.append(element[1].numpy())\n",
    "    \n",
    "for element in xsmall_val_dataset.unbatch():\n",
    "    X_train_xsmall.append(element[0].numpy())\n",
    "    y_train_xsmall.append(element[1].numpy())\n",
    "\n",
    "X_train_xsmall = pd.DataFrame(X_train_xsmall)\n",
    "y_train_xsmall = pd.DataFrame(y_train_xsmall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# II. Train Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.1 Small independent dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.1.a Define mutli-output Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_multi_RF = RandomForestRegressor(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.1.b Fit mutli-output Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../saved_models/concentrations/small_multi_RF/time']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.exists(\"../saved_models/concentrations/small_multi_RF\"):\n",
    "    os.makedirs(\"../saved_models/concentrations/small_multi_RF\")\n",
    "start = time.time()\n",
    "small_multi_RF.fit(X_train_small, y_train_small)\n",
    "time_small = time.time() - start\n",
    "joblib.dump(small_multi_RF, \"../saved_models/concentrations/small_multi_RF/model\")\n",
    "joblib.dump(time_small, \"../saved_models/concentrations/small_multi_RF/time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.1.c Define single-output Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_inde_RFs = []\n",
    "\n",
    "for i in range(48):\n",
    "    small_inde_RFs.append(RandomForestRegressor(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.1.d Fit single-output Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(48):\n",
    "    start = time.time()\n",
    "    small_inde_RFs[i].fit(X_train_small, y_train_small[i])\n",
    "    time_small_inde = time.time() - start\n",
    "    if not os.path.exists(\"../saved_models/concentrations/small_single_RF/metabolite_{}\".format(i)):\n",
    "        os.makedirs(\"../saved_models/concentrations/small_single_RF/metabolite_{}\".format(i))\n",
    "    joblib.dump(small_inde_RFs[i], \"../saved_models/concentrations/small_single_RF/metabolite_{}/model\".format(i))\n",
    "    joblib.dump(time_small_inde, \"../saved_models/concentrations/small_single_RF/metabolite_{}/time\".format(i))\n",
    "    print('\\n', '\\n', '####', '\\n', '\\n', 'Model number {} has been trained in {} seconds !'\n",
    "          .format(i, time_small_inde), '\\n', '\\n', '####', '\\n', '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.1.e Define partial least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_pls = PLSRegression(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.1.f Fit partial least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"../saved_models/concentrations/small_pls\"):\n",
    "    os.makedirs(\"../saved_models/concentrations/small_pls\")\n",
    "start = time.time()\n",
    "small_pls.fit(X_train_small, y_train_small)\n",
    "time_small = time.time() - start\n",
    "joblib.dump(small_pls, \"../saved_models/concentrations/small_pls/model\")\n",
    "joblib.dump(time_small, \"../saved_models/concentrations/small_pls/time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.2 Large independent dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2.a Define mutli-output Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_multi_RF = RandomForestRegressor(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2.b Fit mutli-output Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"../saved_models/concentrations/large_multi_RF\"):\n",
    "    os.makedirs(\"../saved_models/concentrations/large_multi_RF\")\n",
    "start = time.time()\n",
    "large_multi_RF.fit(X_train_large, y_train_large)\n",
    "time_large = time.time() - start\n",
    "joblib.dump(large_multi_RF, \"../saved_models/concentrations/large_multi_RF/model\")\n",
    "joblib.dump(time_large, \"../saved_models/concentrations/large_multi_RF/time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2.c Define single-output Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_inde_RFs = []\n",
    "\n",
    "for i in range(48):\n",
    "    large_inde_RFs.append(RandomForestRegressor(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2.d Fit single-output Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(48):\n",
    "    start = time.time()\n",
    "    large_inde_RFs[i].fit(X_train_large, y_train_large[i])\n",
    "    time_large_inde = time.time() - start\n",
    "    if not os.path.exists(\"../saved_models/concentrations/large_single_RF/metabolite_{}\".format(i)):\n",
    "        os.makedirs(\"../saved_models/concentrations/large_single_RF/metabolite_{}\".format(i))\n",
    "    joblib.dump(large_inde_RFs[i], \"../saved_models/concentrations/large_single_RF/metabolite_{}/model\".format(i))\n",
    "    joblib.dump(time_large_inde, \"../saved_models/concentrations/large_single_RF/metabolite_{}/time\".format(i))\n",
    "    print('\\n', '\\n', '####', '\\n', '\\n', 'Model number {} has been trained in {} seconds !'\n",
    "          .format(i, time_large_inde), '\\n', '\\n', '####', '\\n', '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2.e Define partial least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_pls = PLSRegression(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2.f Fit partial least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"../saved_models/concentrations/large_pls\"):\n",
    "    os.makedirs(\"../saved_models/concentrations/large_pls\")\n",
    "start = time.time()\n",
    "large_pls.fit(X_train_large, y_train_large)\n",
    "time_large = time.time() - start\n",
    "joblib.dump(large_pls, \"../saved_models/concentrations/large_pls/model\")\n",
    "joblib.dump(time_large, \"../saved_models/concentrations/large_pls/time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.3 Exrtra small independent dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.3.a Define mutli-output Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "xsmall_multi_RF = RandomForestRegressor(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.3.b Fit mutli-output Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"../saved_models/concentrations/xsmall_multi_RF\"):\n",
    "    os.makedirs(\"../saved_models/concentrations/xsmall_multi_RF\")\n",
    "start = time.time()\n",
    "xsmall_multi_RF.fit(X_train_xsmall, y_train_xsmall)\n",
    "time_xsmall = time.time() - start\n",
    "joblib.dump(xsmall_multi_RF, \"../saved_models/concentrations/xsmall_multi_RF/model\")\n",
    "joblib.dump(time_xsmall, \"../saved_models/concentrations/xsmall_multi_RF/time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.3.c Define single-output Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xsmall_inde_RFs = []\n",
    "\n",
    "for i in range(48):\n",
    "    xsmall_inde_RFs.append(RandomForestRegressor(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.3.d Fit single-output Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(48):\n",
    "    start = time.time()\n",
    "    xsmall_inde_RFs[i].fit(X_train_xsmall, y_train_xsmall[i])\n",
    "    time_xsmall_inde = time.time() - start\n",
    "    if not os.path.exists(\"../saved_models/concentrations/xsmall_single_RF/metabolite_{}\".format(i)):\n",
    "        os.makedirs(\"../saved_models/concentrations/xsmall_single_RF/metabolite_{}\".format(i))\n",
    "    joblib.dump(xsmall_inde_RFs[i], \"../saved_models/concentrations/xsmall_single_RF/metabolite_{}/model\".format(i))\n",
    "    joblib.dump(time_xsmall_inde, \"../saved_models/concentrations/xsmall_single_RF/metabolite_{}/time\".format(i))\n",
    "    print('\\n', '\\n', '####', '\\n', '\\n', 'Model number {} has been trained in {} seconds !'\n",
    "          .format(i, time_xsmall_inde), '\\n', '\\n', '####', '\\n', '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.3.e Define partial least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xsmall_pls = PLSRegression(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.3.f Fit partial least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"../saved_models/concentrations/xsmall_pls\"):\n",
    "    os.makedirs(\"../saved_models/concentrations/xsmall_pls\")\n",
    "start = time.time()\n",
    "xsmall_pls.fit(X_train_xsmall, y_train_xsmall)\n",
    "time_xsmall = time.time() - start\n",
    "joblib.dump(xsmall_pls, \"../saved_models/concentrations/xsmall_pls/model\")\n",
    "joblib.dump(time_xsmall, \"../saved_models/concentrations/xsmall_pls/time\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
